# QA Black-Box Case Studies

**Author:** Mpumelelo T. Nxazonke
**Focus:** Quality Engineering | UX Risk Analysis | Systems Thinking

## Overview

This repository contains structured black-box QA and UX case studies conducted on publicly accessible web applications.

The objective is to demonstrate:

 * SDET-level analytical thinking
 * Risk-based quality assessment
 * User-centered evaluation
 * Clear, professional technical documentation

All analyses are performed without source code access and are based strictly on observable system behavior.

## Professional Intent

These case studies exist to:

* Apply quality engineering principles to real-world systems
* Identify usability, accessibility, and performance risks
* Evaluate clarity of system purpose and user flow
* Practice structured, evidence-based reporting
* Strengthen product-level quality thinking

This repository reflects how I approach systems when external to the codebase — similar to onboarding into an unfamiliar production environment.

## Method Constraints

Each review is conducted under strict black-box conditions:

* No repository access
* No backend visibility
* No privileged environments
* No security probing
* No speculative assumptions

Assessment inputs include:

* Public UI behavior
* Navigation flows
* Interaction patterns
* Load/performance perception
* Accessibility signals

## Evaluation Framework

Each case study follows a consistent QA structure:

1. Context & Intended System Purpose
2. First-Impression Analysis (5–10 second clarity rule)
3. Information Architecture & Navigation
4. Cognitive Load & Interaction Patterns
5. Accessibility & Inclusive Design Signals
6. Performance Perception vs UX Impact
7. Error Handling & Edge Case Observations
8. Risk Classification Matrix
9. Improvement Recommendations

## What These Case Studies Emphasize

* Risk-based thinking
* Product-level quality awareness
* Structured documentation
* Clear separation of observation vs inference
* Neutral, professional language

Each case study evaluates the system experience, not the individual behind it.

## Repository Structure

```
/reviews
 ├─ R001_Portfolio_WebApp.md
 ├─ R002_SaaS_Landing_Page.md
 └─ R003_Dashboard_Interface.md

/templates
 └─ QA_BlackBox_Template.md
```
## Alignment With SDET Practice

While these reviews are manual and observational in nature, the thinking process mirrors core SDET responsibilities:

* Identifying risk before automation
* Clarifying expected vs observed behavior
* Recognizing UX defects that impact conversion or trust
* Translating ambiguity into structured documentation

Automation is most effective when built on disciplined observation.
These case studies represent the foundation of that discipline.

## Disclaimer

These case studies are:

* Educational
* Non-commercial
* Based solely on publicly observable behavior

If you are a system owner and would like clarification or amendment, please open an issue.